{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccosmin97/IDC-Prostate_segmentation/blob/main/IDC_notebooks/idc-prostate_segmentation_promised24_prostateX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnbkuvxW0Ntp"
      },
      "source": [
        "# Prostate segmentation on IDC collection -- ProstateX\n",
        "*   Dataset : [ProstateX](https://portal.imaging.datacommons.cancer.gov/explore/filters/?collection_id=prostatex)\n",
        "*   Goal : Prostate segmentation using D24 Promise nnUnet pre-trained model, one T2 modality input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auth login"
      ],
      "metadata": {
        "id": "Db4ansTyzqZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Colab"
      ],
      "metadata": {
        "id": "a8GPDXZW00j5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#colab \n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "XSg6W2HXzsoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drive setup for upload results"
      ],
      "metadata": {
        "id": "WbhEtAA70vjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# #drive mount\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# ##setup paths\n",
        "# path_drive_root = \"/content/drive/MyDrive/\"\n",
        "# drive_exp_root_name = \"IDC\" \n",
        "# data = \"prostatex\"\n",
        "# pre_trained_mod = \"task024-promise\"\n",
        "# timestamp = \"2022_07_11\"#year_month_day"
      ],
      "metadata": {
        "id": "ysgh2HbT0ym3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #personal drive path -- make sure folder exists in google drive\n",
        "# path_experiment = os.path.join(path_drive_root,\n",
        "#                                drive_exp_root_name,\n",
        "#                                data,\n",
        "#                                pre_trained_mod,\n",
        "#                                timestamp)\n",
        "\n",
        "# if not os.path.exists(path_experiment):\n",
        "#   !mkdir -p $path_experiment"
      ],
      "metadata": {
        "id": "93gVfB_i0uBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYHTAtTsUgdB"
      },
      "source": [
        "# Global variables"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables used for resampling -- inference -- setup labelID for ground truth segs"
      ],
      "metadata": {
        "id": "yzDbwBXyvWVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IDC collection for paths setup\n",
        "collection_name = \"prostateX\"\n",
        "##nnunet\n",
        "model_type = '3d_fullres'#other options are '2d',..\n",
        "##labelID seg retrieval -- conform to dicom standards\n",
        "ground_truth_cat_CodeMeaning = 'Anatomical Structure'\n",
        "ground_truth_type_CodeMeaning = 'Prostate'"
      ],
      "metadata": {
        "id": "bMsV_GPNvcip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global paths"
      ],
      "metadata": {
        "id": "x-UJO1MlvTHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC_bUbUTUgBs"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "\n",
        "#ProstateX\n",
        "os.environ[\"qin_prostate_rep_root\"] = os.path.join(os.getcwd(), collection_name)\n",
        "os.environ[\"qin_prostate_rep_dicom\"] = os.path.join(os.environ[\"qin_prostate_rep_root\"], \"dicom\")\n",
        "os.environ[\"qin_prostate_rep_nii\"] = os.path.join(os.environ[\"qin_prostate_rep_root\"], \"nii\")\n",
        "os.environ[\"qin_prostate_rep_nrrd\"] = os.path.join(os.environ[\"qin_prostate_rep_root\"], \"nrrd\")\n",
        "os.environ[\"qin_prostate_rep_analysis\"] = os.path.join(os.environ[\"qin_prostate_rep_root\"], \"results\")\n",
        "os.environ[\"qin_prostate_rep_analysis_verbose\"] = os.path.join(os.environ[\"qin_prostate_rep_root\"], \"results_verbose\")\n",
        "\n",
        "\n",
        "#resampled data -- To t2 mod\n",
        "os.environ[\"qin_prostate_rep_root_resampled\"] = os.path.join(os.environ[\"qin_prostate_rep_root\"], \"resampled\")\n",
        "os.environ[\"qin_prostate_rep_nii_resampled\"] = os.path.join(os.environ[\"qin_prostate_rep_root_resampled\"], \"nii\")\n",
        "os.environ[\"qin_prostate_rep_nrrd_resampled\"] = os.path.join(os.environ[\"qin_prostate_rep_root_resampled\"], \"nrrd\")\n",
        "\n",
        "#nnunet\n",
        "os.environ[\"nnUNet\"] = os.path.join(os.getcwd(), \"nnUNet\")\n",
        "os.environ[\"nnUNet_data\"] = os.path.join(os.environ[\"nnUNet\"], \"data\")\n",
        "os.environ['nnUNet_raw_data_base'] = os.path.join(os.environ[\"nnUNet_data\"], \"nnUNet_raw_data\")\n",
        "os.environ['nnUNet_preprocessed'] = os.path.join(os.environ[\"nnUNet_data\"], \"processed\")\n",
        "os.environ[\"nnUNet_models\"] = os.path.join(os.environ[\"nnUNet\"], \"models\")\n",
        "os.environ[\"RESULTS_FOLDER\"] = os.path.join(os.environ[\"nnUNet\"], \"output\", \"preds\")\n",
        "os.environ[\"nnUNet_preds_resampled\"] = os.path.join(os.environ[\"nnUNet\"], \"output\", \"preds_resampled\")\n",
        "os.environ[\"nnUNet_raw_data\"] = os.path.join(os.environ[\"nnUNet\"], \"raw_data\")\n",
        "#path where model pre-trained weights are stored\n",
        "os.environ[\"PATH_TO_MODEL_FILE\"] = os.path.join(os.environ[\"nnUNet\"], \"models\", \"Task024_Promise.zip\")\n",
        "\n",
        "#misc\n",
        "os.environ[\"IDC_Downloads\"] = os.path.join(os.getcwd(), \"IDC_DL\")\n",
        "os.environ[\"IDC_Downloads_Sorted\"] = os.path.join(os.getcwd(), \"IDC_DL\", \"Sorted\")\n",
        "\n",
        "#create dirs for specific folders names\n",
        "for key, path in os.environ.items():\n",
        "  check_patterns = [True for el in [\"qin\", \"nnunet\", \"IDC\", \"nnUNet\"] if el in key]\n",
        "  if True in check_patterns:\n",
        "    !mkdir -p $path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1ZYYVPHz_xm"
      },
      "source": [
        "# Setup GCP Project ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1EN9Dnz0CU4"
      },
      "outputs": [],
      "source": [
        "project_id = \"idc-nlst-unet-seg\" # #YOUR_PROJECT ID\n",
        "os.environ[\"GCP_PROJECT_ID\"] = project_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aru3sCveZjh7"
      },
      "source": [
        "# Download nnUnet pre-trained model on prostate decathlon data -- task24 -- personal dropbox\n",
        "\n",
        "nnUnet pre-trained models zip files can also be found [here](https://zenodo.org/record/4003545#.YsWmH-zMLt8)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPo9DgA7tKHm",
        "outputId": "d43ba634-02c2-4bff-93f3-8bdbe8b4e76a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnUNet/models\n"
          ]
        }
      ],
      "source": [
        "print(os.environ[\"nnUNet_models\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzPWnwbqB-Bt",
        "outputId": "ea9a2649-8da7-40c4-a616-c0dbb44fd8b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-14 17:38:25--  https://www.dropbox.com/s/u9m37l8et4hgu4h/Task024_Promise.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18, 2620:100:6030:18::a27d:5012\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/u9m37l8et4hgu4h/Task024_Promise.zip [following]\n",
            "--2022-07-14 17:38:26--  https://www.dropbox.com/s/raw/u9m37l8et4hgu4h/Task024_Promise.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3efea90de4ec71d2f506474aa2.dl.dropboxusercontent.com/cd/0/inline/BpG10sapxWLkvV5X_fHN8_5TuiMTBeAwlWavtoJxnkzSFXwRjBhfc2qZP-JTb8yKPni_gC_-1JRDRYsPSNw7cGttOC5kEieJ8Hm9PEbE_oL8nl1CUbZj3BeggwgyRY59tx4lfw_lh2ASUgjQXdMadDA5tQMgNIgXJXtig6RXvcPGjg/file# [following]\n",
            "--2022-07-14 17:38:26--  https://uc3efea90de4ec71d2f506474aa2.dl.dropboxusercontent.com/cd/0/inline/BpG10sapxWLkvV5X_fHN8_5TuiMTBeAwlWavtoJxnkzSFXwRjBhfc2qZP-JTb8yKPni_gC_-1JRDRYsPSNw7cGttOC5kEieJ8Hm9PEbE_oL8nl1CUbZj3BeggwgyRY59tx4lfw_lh2ASUgjQXdMadDA5tQMgNIgXJXtig6RXvcPGjg/file\n",
            "Resolving uc3efea90de4ec71d2f506474aa2.dl.dropboxusercontent.com (uc3efea90de4ec71d2f506474aa2.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uc3efea90de4ec71d2f506474aa2.dl.dropboxusercontent.com (uc3efea90de4ec71d2f506474aa2.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BpEO5EqV_vKNaARoEWRXpM-1esPqQHshydyrJRwff26VKRaPceSJ8wd8fThutFFNDMjA4Uz8hGVFXpgqEv2RY3yIhOxtsinsLM5P9jNkeRhOVnhHZqSXdV9iGPSOhycuGmqB8UffSHm5b9XqxvzZbsPFjSzKIa1HAhHw-0PVk4tIryKAPI-z1My3ty8kyVUTo37--B-71390dOyFKLthX6-W8NmRVWuxwhsu9Bm4AL66eXqIWgzfHc8M8DZR0wxaj6HWZgEiQqiaaIyF_8aG_gqFaTUOcbqCxWHReZG9rgY3lGgDjgbME5ISZaqe-8FfdSReWGYLss_kPuU2kJrjA_3TV4TfddWvoLhE_kPP6K3s5l9Y7UxJCXBslw-_bCT5DIT6JV_JXwvCZAb9lpB8X_cLaP2yCk-uqwIsKe-umLKTig/file [following]\n",
            "--2022-07-14 17:38:27--  https://uc3efea90de4ec71d2f506474aa2.dl.dropboxusercontent.com/cd/0/inline2/BpEO5EqV_vKNaARoEWRXpM-1esPqQHshydyrJRwff26VKRaPceSJ8wd8fThutFFNDMjA4Uz8hGVFXpgqEv2RY3yIhOxtsinsLM5P9jNkeRhOVnhHZqSXdV9iGPSOhycuGmqB8UffSHm5b9XqxvzZbsPFjSzKIa1HAhHw-0PVk4tIryKAPI-z1My3ty8kyVUTo37--B-71390dOyFKLthX6-W8NmRVWuxwhsu9Bm4AL66eXqIWgzfHc8M8DZR0wxaj6HWZgEiQqiaaIyF_8aG_gqFaTUOcbqCxWHReZG9rgY3lGgDjgbME5ISZaqe-8FfdSReWGYLss_kPuU2kJrjA_3TV4TfddWvoLhE_kPP6K3s5l9Y7UxJCXBslw-_bCT5DIT6JV_JXwvCZAb9lpB8X_cLaP2yCk-uqwIsKe-umLKTig/file\n",
            "Reusing existing connection to uc3efea90de4ec71d2f506474aa2.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2258526938 (2.1G) [application/zip]\n",
            "Saving to: ‘/content/nnUNet/models/Task024_Promise.zip’\n",
            "\n",
            "/content/nnUNet/mod 100%[===================>]   2.10G  16.8MB/s    in 2m 13s  \n",
            "\n",
            "2022-07-14 17:40:42 (16.1 MB/s) - ‘/content/nnUNet/models/Task024_Promise.zip’ saved [2258526938/2258526938]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# this will usually take between one and five minutes (but can sometimes take up to eight)\n",
        "seg_model_url = \"https://www.dropbox.com/s/u9m37l8et4hgu4h/Task024_Promise.zip?dl=0\"\n",
        "out_path_mod = os.path.join(os.environ[\"nnUNet_models\"], \"Task024_Promise.zip\")#\"/content/nnUnet/models/Task024_Promise.zip\"\n",
        "!wget -O $out_path_mod $seg_model_url"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRtmCas7dT6D"
      },
      "source": [
        "# Setup of the Colab VM\n",
        "\n",
        "\n",
        "\n",
        "In the following cells we will confirm you have a GPU before doing anything else, and will install and import all the Python dependencies. \n",
        "\n",
        "The main python packages we need to install are:\n",
        "* `nnunet` - which is the [codebase for the nn-UNet framework](https://github.com/MIC-DKFZ/nnUNet) we are going to be using for the segmentation step;\n",
        "* `pydicom`, a Python [package](https://github.com/pydicom/pydicom) that lets the use read, modify, and write DICOM data in an easy \"pythonic\" way - that we are going to use to distinguish different DICOM objects from each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLvysANUArnm"
      },
      "source": [
        "## GPU checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pf2j172mddvK"
      },
      "outputs": [],
      "source": [
        "# check wether the Colab Instance was correctly initialized with a GPU instance\n",
        "gpu_list = !nvidia-smi --list-gpus\n",
        "\n",
        "has_gpu = False if \"failed\" in gpu_list[0] else True\n",
        "\n",
        "if not has_gpu:\n",
        "  print(\"Your Colab VM does not have a GPU - check \\\"Runtime > Change runtime type\\\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL6xCvo3eKQ0",
        "outputId": "d1bf3aff-6f0a-4e29-9618-522e5d1e73f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul 14 17:40:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# check which model of GPU the notebook is equipped with - a Tesla K80 or T4\n",
        "# T4 is the best performing on the two - and can about half the GPU processing time\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJhwBz2ABT_p"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "Here we will configure the Linux environment variables needed to run the nnU-Net pipeline. \n",
        "\n",
        "Three main variables are needed by default to run the nnU-Net segmentation pipelines:\n",
        "* `nnUNet_raw_data_base` is the path to the folder where the segmentation pipeline expects to find the data to process;\n",
        "* `nnUNet_preprocessed` is the path to the folder where the preprocessed data are saved;\n",
        "* `RESULTS_FOLDER` is the path to the folder storing by default the model weights and, in our case, for simplicity, the segmentation masks produced by the pipeline.\n",
        "\n",
        "We will use the additional variable `PATH_TO_MODEL_FILE` to point to the location where the pre-trained model weights for the chosen model will be stored (more on this later).\n",
        "\n",
        "Please notice that these variables need to be set using `os.environ[]` in Google Colab - as `!export` is not sufficient to guarantee the variables are kept from one cell to the other. For more in-depth information regarding what the nnU-Net framework uses these folders for, please visit [the dedicated nnU-Net documentation page](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/setting_up_paths.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40E3HnI5A0SX"
      },
      "source": [
        "## Install command-line tools\n",
        "\n",
        "\n",
        "[Plastimatch](https://plastimatch.org/index.html) is considered to be the swiss army knife of medical images processing: we will use it to convert DICOM (CT, RTSTRUCT) series to NRRD files - but it can be used for a multitude of other tasks, such as registration, resampling, cropping, and computing statistics to name a few. Plastimatch is also available as a 3DSlicer plug-in and can be used directly from the Slicer GUI.\n",
        "\n",
        "For the sake of clarity and simplicity, we will call Plastimatch from a very simple [Python wrapper](https://github.com/denbonte/pyplastimatch) written for the occasion (unfortunately, Plastimatch does not provide an official one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZL6-ByHA7XY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!sudo apt update\n",
        "\n",
        "!sudo apt install plastimatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMovHnKgBEfC",
        "outputId": "922e18bd-3e80-4871-9824-745f45a9927a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plastimatch version 1.7.0\n"
          ]
        }
      ],
      "source": [
        "!echo $(plastimatch --version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_8zlhmdo0HD"
      },
      "source": [
        "[dcmqi](https://github.com/QIICR/dcmqi) is an open source library that can help with the conversion between imaging research formats and the standard DICOM representation for image analysis results. More specifically, you can use dcmqi convert DICOM Segmentation objects (DICOM SEG) into research formats, such as NIfTI and NRRD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAkmz4jApGh8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://github.com/QIICR/dcmqi/releases/download/v1.2.4/dcmqi-1.2.4-linux.tar.gz\n",
        "!tar zxvf dcmqi-1.2.4-linux.tar.gz\n",
        "!cp dcmqi-1.2.4-linux/bin/* /usr/local/bin/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFRWendbBH72"
      },
      "source": [
        "Finally, we are going to install [Subversion](https://subversion.apache.org/), a tool that will allow us to clone GitHub repositories only partially (to save time and space)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBEJRe-2BKah"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!sudo apt install subversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI1_BixWBN1O",
        "outputId": "3723cbb2-360f-4861-b292-f053e6d0bb1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "svn, version 1.9.7 (r1800392) compiled May 21 2022, 07:24:25 on x86_64-pc-linux-gnu\n"
          ]
        }
      ],
      "source": [
        "!echo $(svn --version | head -n 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ev-JlpCAuMs"
      },
      "source": [
        "## Install Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XMzq-8nRvKd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install nnunet\n",
        "!pip install pydicom\n",
        "!pip install nibabel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62yhEkkjITzn"
      },
      "source": [
        "Unpack and install model we downloaded earlier (under `PATH_TO_MODEL_FILE`). This step can take about 1-2 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOVsPuzxIOXX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!nnUNet_install_pretrained_model_from_zip $PATH_TO_MODEL_FILE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP1tahM9tzlm"
      },
      "source": [
        "Next we set up few things to help with visualization of the segmentations later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cURjj8rzAa2L",
        "outputId": "04ede329-d00b-410e-bc35-a188865ed31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Tensorflow 1 is deprecated, and support will be removed on August 1, 2022.\n",
            "After that, `%tensorflow_version 1.x` will throw an error.\n",
            "\n",
            "Your notebook should be updated to use Tensorflow 2.\n",
            "See the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "Python version               :  3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "Numpy version                :  1.21.6\n",
            "TensorFlow version           :  1.15.2\n",
            "Keras (stand-alone) version  :  2.3.1\n",
            "\n",
            "This Colab instance is equipped with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import csv\n",
        "import random\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import csv\n",
        "import json\n",
        "\n",
        "import nibabel as nib\n",
        "\n",
        "import time\n",
        "import gdown\n",
        "\n",
        "import json\n",
        "import pprint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pydicom\n",
        "import nibabel as nib\n",
        "import SimpleITK as sitk\n",
        "\n",
        "from medpy.metric.binary import dc as dice_coef\n",
        "from medpy.metric.binary import hd as hausdorff_distance\n",
        "from medpy.metric.binary import asd as avg_surf_distance\n",
        "\n",
        "from medpy.filter.binary import largest_connected_component\n",
        "\n",
        "# use the \"tensorflow_version\" magic to make sure TF 1.x is imported\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "print(\"Python version               : \", sys.version.split('\\n')[0])\n",
        "print(\"Numpy version                : \", np.__version__)\n",
        "print(\"TensorFlow version           : \", tf.__version__)\n",
        "print(\"Keras (stand-alone) version  : \", keras.__version__)\n",
        "\n",
        "print(\"\\nThis Colab instance is equipped with a GPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrAh2kjqb2Be",
        "outputId": "af6110a3-cc1b-46b7-feac-ac906312d511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A    pyplastimatch/__init__.py\n",
            "A    pyplastimatch/pyplastimatch.py\n",
            "A    pyplastimatch/utils\n",
            "A    pyplastimatch/utils/__init__.py\n",
            "A    pyplastimatch/utils/data.py\n",
            "A    pyplastimatch/utils/eval.py\n",
            "A    pyplastimatch/utils/viz.py\n",
            "Checked out revision 18.\n"
          ]
        }
      ],
      "source": [
        "# PyPlastimatch - python wrapper for Plastimatch (and interactive notebook visualisation)\n",
        "!svn checkout https://github.com/AIM-Harvard/pyplastimatch/trunk/pyplastimatch pyplastimatch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsePTNBmM9sw",
        "outputId": "79351ebb-3b5c-433e-d32e-c4e430c916e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dicomsort'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 130 (delta 0), reused 1 (delta 0), pack-reused 126\u001b[K\n",
            "Receiving objects: 100% (130/130), 44.12 KiB | 627.00 KiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n"
          ]
        }
      ],
      "source": [
        "# dicomsort is the pythong package that can sort DICOM files into\n",
        "# folder organization based on user-specified DICOM attributes\n",
        "!git clone https://github.com/pieper/dicomsort.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s9aRassGOQ_"
      },
      "outputs": [],
      "source": [
        "from pyplastimatch import pyplastimatch as pypla\n",
        "from pyplastimatch.utils import viz as viz_utils\n",
        "from pyplastimatch.utils import data as data_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duil1tviGWaG"
      },
      "source": [
        "# Data selection, downloading and structuring\n",
        "\n",
        "We want to select here the collection named qin-prostate repeatibility, and more particularly the two timepoints per patient ID for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDHCwK-TG4n2"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naJ5OAKZnZpG"
      },
      "source": [
        "In order to use data hosted by IDC effectively, you will need to utilize metadata to navigate what data is available and to select specific files that are relevant in your analysis. The main metadata table you will need for this purpose is the [`bigquery-public-data.idc_current.dicom_all`](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=idc_current&t=dicom_all&page=table) table.\n",
        "\n",
        "This query has one row per file hosted by IDC. All of IDC data is in DICOM format, and each of the rows in this table will have all of the DICOM attributes extracted from a given file. It will also have various columns containing non-DICOM metadata, such as the name of the collection where the file is included, size of the file, and URL that can be used to retrieve that file.\n",
        "\n",
        "To query IDC BigQuery tables, you can use one of the following approaches:\n",
        "1. `%%bigquery` magic will allow you to define your query in plain SQL, and load the result of the query into a Pandas dataframe.\n",
        "2. [BigQuery Python API](https://googleapis.dev/python/bigquery/latest/index.html) is more flexible in allowing you to parameterize your query.\n",
        "3. [Google Cloud BigQuery console](https://console.cloud.google.com/bigquery) is very convenient for interactive query exploration of tables.\n",
        "4. [`gcloud bq`](https://cloud.google.com/bigquery/docs/bq-command-line-tool) is the command line tool that comes as part of [Cloud SDK](https://cloud.google.com/sdk) and is convenient for scripting interactions from the shell. Cloud SDK is preinstalled on Colab.\n",
        "\n",
        "In the following cells we will utilize `%%bigquery`, Python BigQuery SDK and BigQuery console for working with IDC BigQuery tables.\n",
        "\n",
        "First, to verify that you are authenticated, and your project ID is working, let's run a test query against IDC BigQuery table to get the summary statistics about the  of data available in IDC.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9YKMGVvVZX_"
      },
      "source": [
        "Given `SeriesInstanceUID` value identifying the image series, we can query the IDC metadata table to get the list of files (defined by the Google Storage URLs) corresponding to this series.\n",
        "\n",
        "All of the DICOM metadata for each of the DICOM files is available in the BigQuery table we will be querying. We will get not just the `gcs_url`, but also identifiers for the Study, Series and Instance, to better understand organization of data, and since `StudyInstanceUID` will be handy later when we get to the visualization of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7INoX4rgTp7O"
      },
      "source": [
        "## Data selection -- BigQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation"
      ],
      "metadata": {
        "id": "jfDSklhyFWpa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joRbZ81GWNz1"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "bq_client = bigquery.Client(os.environ[\"GCP_PROJECT_ID\"])\n",
        "selection_query = f\"\"\"\n",
        "WITH\n",
        "# studies that have mr volumes\n",
        "mr_studies AS(\n",
        "  SELECT\n",
        "    dicom_all_mr.SOPInstanceUID as SOPInstanceUID, \n",
        "    dicom_all_mr.StudyInstanceUID as StudyInstanceUID,\n",
        "    '' AS segPropertyTypeCodeMeaning, \n",
        "    '' AS segPropertyCategoryCodeMeaning \n",
        "  FROM\n",
        "    `bigquery-public-data.idc_current.dicom_all` as dicom_all_mr\n",
        "  WHERE\n",
        "    Modality = 'MR'\n",
        "    AND collection_id = 'prostatex'\n",
        "    AND SeriesDescription LIKE '%t2_tse_tra%'),\n",
        " \n",
        "# studies that have segmentations for the whole prostate\n",
        "seg_studies AS (\n",
        "SELECT\n",
        "  dicom_all_seg.SOPInstanceUID as SOPInstanceUID,\n",
        "  dicom_all_seg.StudyInstanceUID as StudyInstanceUID,\n",
        "  segmentations.SegmentedPropertyType.CodeMeaning as segPropertyTypeCodeMeaning,\n",
        "  segmentations.SegmentedPropertyCategory.CodeMeaning as segPropertyCategoryCodeMeaning\n",
        "\n",
        "FROM\n",
        "  `bigquery-public-data.idc_current.dicom_all` AS dicom_all_seg\n",
        "JOIN\n",
        "  `bigquery-public-data.idc_current.segmentations` AS segmentations\n",
        "ON\n",
        "  dicom_all_seg.SOPInstanceUID = segmentations.SOPInstanceUID\n",
        "WHERE\n",
        "  collection_id = \"prostatex\"\n",
        "AND \n",
        "  segmentations.SegmentedPropertyType.CodeMeaning = 'Prostate'\n",
        "AND \n",
        "  segmentations.SegmentedPropertyCategory.CodeMeaning = 'Anatomical Structure'),\n",
        "  \n",
        "union_mr_seg AS(\n",
        "  SELECT\n",
        "    mr_studies.SOPInstanceUID, \n",
        "    mr_studies.segPropertyTypeCodeMeaning, \n",
        "    mr_studies.segPropertyCategoryCodeMeaning, \n",
        "  FROM \n",
        "    mr_studies\n",
        "  JOIN\n",
        "    seg_studies\n",
        "  ON\n",
        "    mr_studies.StudyInstanceUID = seg_studies.StudyInstanceUID\n",
        "  UNION ALL\n",
        "  SELECT\n",
        "    seg_studies.SOPInstanceUID, \n",
        "    seg_studies.segPropertyTypeCodeMeaning, \n",
        "    seg_studies.segPropertyCategoryCodeMeaning, \n",
        "  FROM \n",
        "    seg_studies)\n",
        "\n",
        "SELECT \n",
        "  dc_all.gcs_url,\n",
        "  dc_all.StudyInstanceUID, \n",
        "  dc_all.SeriesInstanceUID, \n",
        "  dc_all.SOPInstanceUID, \n",
        "  dc_all.PatientID,\n",
        "  dc_all.Modality, \n",
        "  dc_all.SeriesDescription,\n",
        "  union_mr_seg.segPropertyTypeCodeMeaning,\n",
        "  union_mr_seg.segPropertyCategoryCodeMeaning,\n",
        "  (SELECT SeriesInstanceUID FROM UNNEST(dc_all.ReferencedSeriesSequence)) AS RefSerieUID \n",
        "FROM \n",
        "  `bigquery-public-data.idc_current.dicom_all` as dc_all\n",
        "JOIN\n",
        "  union_mr_seg\n",
        "ON \n",
        "  dc_all.SOPInstanceUID = union_mr_seg.SOPInstanceUID\"\"\" "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selection_result = bq_client.query(selection_query)\n",
        "selection_df = selection_result.result().to_dataframe()"
      ],
      "metadata": {
        "id": "j1PtIeNJ8Qf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomly pick X PatientIDs for the use case - pick 5 by default OR Static selection"
      ],
      "metadata": {
        "id": "SjrQmHbKLykY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBxWO9GlPVT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103cc325-71ed-4fe6-ffc1-ffe65df8f626"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ProstateX-0046'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# # #random PatientID selection\n",
        "# patientID_select = random.sample(list(selection_df.PatientID.values), 1)#X randomly picked PatientIDs \n",
        "\n",
        "# # #static PatientID selection\n",
        "# # patientID_select = [\"ProstateX-0006\"]\n",
        "\n",
        "# selection_df = selection_df[selection_df.PatientID.isin(patientID_select)]\n",
        "# selection_df.PatientID.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOtsKTg8TvCG"
      },
      "source": [
        "## Download gs urls into dcm files and sorting  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3pHlJbcdPq6",
        "outputId": "603c5454-e1e9-4c33-e9ab-4995d10b3a34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique patientIDS that have both t2 axial and seg whole prostate objects : 1\n"
          ]
        }
      ],
      "source": [
        "# selection_df=pd.read_csv(selection_df)#\"t2_and_seg.csv\")\n",
        "print(f\"number of unique patientIDS that have both t2 axial and seg whole prostate objects : {len(sorted(selection_df.PatientID.unique()))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download and sort DCM files"
      ],
      "metadata": {
        "id": "aAq_FbwAtFQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4YXrk6PIkJe"
      },
      "outputs": [],
      "source": [
        "# save the list of GCS URLs into a file\n",
        "selection_manifest = os.path.join(os.environ[\"IDC_Downloads\"], \"idc_manifest.txt\")\n",
        "selection_df[\"gcs_url\"].to_csv(selection_manifest, header=False, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIKSKvW8mdsN",
        "outputId": "adde9a21-fd5d-4a2d-acc2-8db10f28edb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     20      20    1320\n"
          ]
        }
      ],
      "source": [
        "# confirm the resulting manifest has as many lines as the number of rows in the\n",
        "# dataframe we initialized earlier\n",
        "!cat {selection_manifest} |wc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdZSVftdjFPl"
      },
      "outputs": [],
      "source": [
        "# let's make sure the download folder is clean, in case you ran this cell earlier\n",
        "# for a different dataset\n",
        "!rm -rf {os.environ[\"IDC_Downloads\"]+\"/*.dcm\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ydwu1tSYScJ"
      },
      "outputs": [],
      "source": [
        "# download is this simple!\n",
        "%%capture\n",
        "\n",
        "!cat {selection_manifest} | gsutil -m cp -I {os.environ[\"IDC_Downloads\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvlSBfPRdRpz"
      },
      "source": [
        "To facilitate preparation of the data, we will sort the downloaded files into the PatientID/StudyInstanceUID/SeriesInstanceUID hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9aVI7qAbaT0",
        "outputId": "a4be3d38-29c5-4c94-e0f2-427123e1ae5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 0/21 [00:00<?, ?it/s]\r 52% 11/21 [00:00<00:00, 81.05it/s]\r100% 21/21 [00:00<00:00, 121.71it/s]\n",
            "Files sorted\n"
          ]
        }
      ],
      "source": [
        "!python dicomsort/dicomsort.py -k -u {os.environ[\"IDC_Downloads\"]} {os.environ[\"IDC_Downloads_Sorted\"]}/%PatientID/%StudyInstanceUID/%SeriesInstanceUID/%SOPInstanceUID.dcm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewcZsa1rzKHi"
      },
      "source": [
        "Move the sorted data into the right place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ_LAvUGEGxj"
      },
      "outputs": [],
      "source": [
        "rm -rf {os.environ[\"qin_prostate_rep_dicom\"]+\"/*\"}* && mv {os.environ[\"IDC_Downloads_Sorted\"]+\"/*\"} {os.environ[\"qin_prostate_rep_dicom\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z5QylRmj9gw"
      },
      "source": [
        "#Pre-Processing\n",
        "\n",
        "Dicom files are assumed to be sorted this way for further processing :\n",
        "\n",
        "* PatientID\n",
        "  * StudyUID\n",
        "    * SeriesUID\n",
        "      * *.dcm file(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxaZ6eMwQVOb"
      },
      "source": [
        "## conversion methods from DCM to NII/NRRD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2B-4nymgk5I"
      },
      "source": [
        "https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=24283641\n",
        "\n",
        "switch from plastimatch resample method to simple itk for slice spacing issue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZJdr2v-f6qY"
      },
      "outputs": [],
      "source": [
        "def safe_sitk_read(img_list, *args, **kwargs):\n",
        "  \"\"\"\n",
        "  Since the default function just looks at images 0 and 1 to determine slice thickness\n",
        "  and the images are often not correctly alphabetically sorted, much slower\n",
        "  :param img_list:\n",
        "  :return:\n",
        "  \"\"\"\n",
        "  pimg_list = [(sitk.ReadImage(x).GetOrigin(), x) for x in img_list]\n",
        "  s_img_list = [path for _, path in sorted(pimg_list, key = lambda x: x[0][2])] # sort by z\n",
        "  return sitk.ReadImage(s_img_list, *args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkSLspMHgqOV"
      },
      "outputs": [],
      "source": [
        "def convert_mr_to_nii_nrrd(input_path, output_path_root, modality, target_format=\"nii.gz\"):\n",
        "  if not os.path.exists(output_path_root): \n",
        "    !mkdir -p $output_path_root\n",
        "  output_path = os.path.join(output_path_root, input_path.split('/')[-1][:-4] \n",
        "                             + \"_MR_\" + modality\n",
        "                             + \".\" + target_format)\n",
        "  #convert to target format\n",
        "  if not os.path.exists(output_path):\n",
        "    dcm_img = safe_sitk_read(glob.glob(os.path.join(input_path, \"**\", \"*.dcm\"), recursive=True))\n",
        "    sitk.WriteImage(dcm_img, output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdISKxlrg5U7"
      },
      "source": [
        "We will use the [segimage2itkimage tool](https://qiicr.gitbook.io/dcmqi-guide/opening/cmd_tools/seg/segimage2itkimage) from dcmqi to extract individual segments from DICOM SEG series we just downloaded into NII format, saving each segment into a separate file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eav6vNsTg9TL"
      },
      "outputs": [],
      "source": [
        "def convert_seg_to_nii(input_path, output_path):\n",
        "  if not os.path.exists(output_path): \n",
        "    !mkdir -p $output_path\n",
        "  \n",
        "  print(f'input path : {input_path}')\n",
        "  print(f'output_path : {output_path}')\n",
        "  !segimage2itkimage --inputDICOM $input_path --outputDirectory $output_path \\\n",
        "  --outputType nii "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1tYQCkFQZ7A"
      },
      "outputs": [],
      "source": [
        "def convert_dcm_sorted(input_path,output_path):\n",
        "  path_dicom = os.environ[\"qin_prostate_rep_dicom\"] \n",
        "  for serie_folder in sorted(glob.glob(os.path.join(input_path, \"**\", \"**\", \"*\"))):#, recursive = True):\n",
        "    path_serie_dcm_lst = glob.glob(os.path.join(serie_folder, \"*.dcm\"))\n",
        "    type_serie = selection_df[selection_df[\"SeriesInstanceUID\"] == path_serie_dcm_lst[0].split('/')[-2]][\"Modality\"].iloc[0]#'SEG' if pydicom.dcmread(path_serie_dcm_lst[0]).Modality == \"SEG\" else \"MR\"\n",
        "    seriesInstanceUID = serie_folder.split(\"/\")[-1]\n",
        "    studyInstanceUID = serie_folder.split(\"/\")[-2]\n",
        "    patientID = serie_folder.split(\"/\")[-3]\n",
        "    if type_serie == \"SEG\":\n",
        "      #convert to nrrd\n",
        "      convert_seg_to_nii(input_path=path_serie_dcm_lst[0],\n",
        "                              output_path=os.path.join(output_path, \"nii\", \n",
        "                                                       patientID, studyInstanceUID, seriesInstanceUID + \"_SEG\"))\n",
        "    elif type_serie == \"MR\":\n",
        "      #convert to nii\n",
        "      convert_mr_to_nii_nrrd(input_path=serie_folder,\n",
        "                              output_path_root=os.path.join(output_path, \"nii\", \n",
        "                                                       patientID, studyInstanceUID, seriesInstanceUID + \"_MR\"), modality=\"T2\", target_format=\"nii.gz\")\n",
        "      #convert to nrrd\n",
        "      convert_mr_to_nii_nrrd(input_path=serie_folder, \n",
        "                              output_path_root=os.path.join(output_path, \"nrrd\", \n",
        "                                                       patientID, studyInstanceUID, seriesInstanceUID + \"_MR\"), modality=\"T2\", target_format=\"nrrd\")\n",
        "    else:\n",
        "      print(f\"type serie {type_serie} not supported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDE69us5SosB"
      },
      "source": [
        "## Conversion to NII/NRRD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQrcemmAW7tC"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/qin_prostate_root_data/nii/*\n",
        "!rm -rf /content/qin_prostate_root_data/nrrd/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB1YhW33y32e",
        "outputId": "bbdfca8e-8cfe-45d4-b194-6cd296dd27fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input path : /content/prostateX/dicom/ProstateX-0046/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345/1.2.276.0.7230010.3.1.3.1070885483.8220.1599221770.50/1.2.276.0.7230010.3.1.4.1070885483.8220.1599221770.51.dcm\n",
            "output_path : /content/prostateX/nii/ProstateX-0046/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345/1.2.276.0.7230010.3.1.3.1070885483.8220.1599221770.50_SEG\n",
            "dcmqi repository URL: git@github.com:QIICR/dcmqi.git revision: ef9e227 tag: v1.2.4\n",
            "Row direction: 1 -2.03865e-10 2.25069e-11\n",
            "Col direction: 2.05103e-10 0.993961 -0.109734\n",
            "Z direction: -1.97083e-17 0.109734 0.993961\n",
            "Total frames: 114\n",
            "Total frames with unique IPP: 114\n",
            "Total overlapping frames: 0\n",
            "Origin: [-102.57, -104.731, 25.0919]\n"
          ]
        }
      ],
      "source": [
        "convert_dcm_sorted(input_path=os.environ[\"qin_prostate_rep_dicom\"],\n",
        "                   output_path=os.environ[\"qin_prostate_rep_root\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwhGpo_iY8Pt"
      },
      "source": [
        "# Resampling ground truth segmentations to T2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/qin_prostate_root_data/resampled/nii/*\n",
        "!rm -rf /content/qin_prostate_root_data/resampled/nrrd/*"
      ],
      "metadata": {
        "id": "oIf2aI7_Dt_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jId7-hwAGnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb00a048-29c8-467c-ae4d-a6a6c398451e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/prostateX/nii/ProstateX-0046/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345/1.2.276.0.7230010.3.1.3.1070885483.8220.1599221770.50_SEG/1.nii.gz\n"
          ]
        }
      ],
      "source": [
        "nii_lst = glob.glob(os.path.join(os.environ[\"qin_prostate_rep_nii\"], \"**\", \"*_SEG\", \"*.nii.gz\"), recursive=True)\n",
        "for seg_nii in sorted(nii_lst) :\n",
        "  print(seg_nii)\n",
        "  patientID = seg_nii.split('/')[-4]\n",
        "  studyUID = seg_nii.split('/')[-3]\n",
        "  serieUID = seg_nii.split('/')[-2][:-4] #standard serieUID without T2_SEG custom suffix\n",
        "  #get referencedSerieUID from seg corresponding to T2 MR volume \n",
        "  referencedSerieUID = str(selection_df[selection_df[\"SeriesInstanceUID\"] == serieUID][\"RefSerieUID\"].iloc[0])\t\n",
        "  matched_mod = glob.glob(os.path.join(os.environ['qin_prostate_rep_nii'], \n",
        "                                            patientID, studyUID, referencedSerieUID + \"_MR\", \"*.nii*\"))[0]\n",
        "  output_path_seg_root = os.path.join(os.environ[\"qin_prostate_rep_nii_resampled\"],\n",
        "                                  patientID, studyUID,\n",
        "                                  serieUID + \"_SEG\")\n",
        "  if not os.path.exists(output_path_seg_root):\n",
        "    !mkdir -p $output_path_seg_root\n",
        "  resample_args = {\"input\" : seg_nii, \n",
        "                        \"output\" : os.path.join(output_path_seg_root, seg_nii.split('/')[-1]),\n",
        "                        \"fixed\" : matched_mod,\n",
        "                        \"interpolation\" : \"nn\"}\n",
        "  #resample to t2 mod based on study -- not uniform across studies\n",
        "  pypla.resample(verbose = False, **resample_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rIgfkgxkQeS"
      },
      "source": [
        "# Inference -- nnUnet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PfFh2vWBGqm"
      },
      "source": [
        "## Naming Formatting T2 files for nnUnet inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0lAnsWvN6fA"
      },
      "outputs": [],
      "source": [
        "nii_lst = glob.glob(os.path.join(os.environ[\"qin_prostate_rep_nii\"], \"**\", \"*T2*.nii.gz\"), recursive=True)#get nii lst from data\n",
        "nii_mr_t2 = [el for el in nii_lst if el.split('/')[-1].split('.')[-3].split('_')[-1] == \"T2\"]#get T2 lst from nii lst\n",
        "for idx, el_t2 in enumerate(nii_mr_t2):\n",
        "  studyInstanceUID_t2 = el_t2.split('/')[-3]\n",
        "  patientID_t2 = el_t2.split(\"/\")[-4]\n",
        "  #format to nnunet \n",
        "  t2_out_nnunet = os.path.join(os.environ[\"nnUNet_preprocessed\"], \"_\".join([studyInstanceUID_t2, patientID_t2, \"0000\"]) + \".nii.gz\")\n",
        "  #copy to nnUnet folder\n",
        "  !cp $el_t2 $t2_out_nnunet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py5Gl9k-qrG7"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV2MKQsuy6w3",
        "outputId": "04672cd3-c2bf-4c15-a5e2-80232989aa95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "Prostate MR Image Segmentation 2012. \n",
            "Segmentation target is the prostate, \n",
            "Input modalities are 0: T2. \n",
            "Also see https://promise12.grand-challenge.org/\n"
          ]
        }
      ],
      "source": [
        "!nnUNet_print_pretrained_model_info Task024_Promise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrK13UnT0MLy",
        "outputId": "52367298-d337-4b09-b884-14ec3e88da4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input folder path : /content/nnUNet/data/processed\n",
            "output folder path : /content/nnUNet/output/preds\n"
          ]
        }
      ],
      "source": [
        "print(f\"input folder path : \"+os.environ[\"nnUNet_preprocessed\"])\n",
        "print(f\"output folder path : \"+os.environ[\"RESULTS_FOLDER\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo {os.environ[\"nnUNet_preprocessed\"]} "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivhC1cE9NrnE",
        "outputId": "c2bb4290-840b-46fe-9d4f-29ebcd595aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nnUNet/data/processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7E0FZ3mxlaI"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!nnUNet_install_pretrained_model_from_zip $out_path_mod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Gsuoa5aqu4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb783ee8-9c8f-4ca9-c940-5b613c4ebdc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "using model stored in  /content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1\n",
            "This model expects 1 input modalities for each image\n",
            "Found 1 unique case ids, here are some examples: ['1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345_ProstateX-0046']\n",
            "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
            "number of cases: 1\n",
            "number of cases that still need to be predicted: 1\n",
            "emptying cuda cache\n",
            "loading parameters for folds, None\n",
            "folds is None so we will automatically look for output folders (not using 'all'!)\n",
            "found the following folds:  ['/content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0', '/content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1', '/content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2', '/content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3', '/content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4']\n",
            "2022-07-14 17:43:58.560609: Using dummy2d data augmentation\n",
            "using the following model files:  ['/content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model', '/content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model', '/content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model', '/content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model', '/content/nnUNet/output/preds/nnUNet/3d_fullres/Task024_Promise/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model']\n",
            "starting preprocessing generator\n",
            "starting prediction...\n",
            "preprocessing /content/nnUNet/output/preds/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345_ProstateX-0046.nii.gz\n",
            "using preprocessor GenericPreprocessor\n",
            "before crop: (1, 19, 384, 384) after crop: (1, 19, 383, 383) spacing: [3.  0.5 0.5] \n",
            "\n",
            "separate z, order in z is 0 order inplane is 3\n",
            "separate z, order in z is 0 order inplane is 1\n",
            "before: {'spacing': array([3. , 0.5, 0.5]), 'spacing_transposed': array([3. , 0.5, 0.5]), 'data.shape (data is transposed)': (1, 19, 383, 383)} \n",
            "after:  {'spacing': array([2.20004711, 0.61250001, 0.61250001]), 'data.shape (data is resampled)': (1, 26, 313, 313)} \n",
            "\n",
            "(1, 26, 313, 313)\n",
            "This worker has ended successfully, no errors to report\n",
            "predicting /content/nnUNet/output/preds/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345_ProstateX-0046.nii.gz\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (1, 28, 313, 313)\n",
            "patch size: [ 28 256 256]\n",
            "steps (x, y, and z): [[0], [0, 57], [0, 57]]\n",
            "number of tiles: 4\n",
            "computing Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (1, 28, 313, 313)\n",
            "patch size: [ 28 256 256]\n",
            "steps (x, y, and z): [[0], [0, 57], [0, 57]]\n",
            "number of tiles: 4\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (1, 28, 313, 313)\n",
            "patch size: [ 28 256 256]\n",
            "steps (x, y, and z): [[0], [0, 57], [0, 57]]\n",
            "number of tiles: 4\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (1, 28, 313, 313)\n",
            "patch size: [ 28 256 256]\n",
            "steps (x, y, and z): [[0], [0, 57], [0, 57]]\n",
            "number of tiles: 4\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "debug: mirroring True mirror_axes (0, 1, 2)\n",
            "step_size: 0.5\n",
            "do mirror: True\n",
            "data shape: (1, 28, 313, 313)\n",
            "patch size: [ 28 256 256]\n",
            "steps (x, y, and z): [[0], [0, 57], [0, 57]]\n",
            "number of tiles: 4\n",
            "using precomputed Gaussian\n",
            "prediction done\n",
            "inference done. Now waiting for the segmentation export to finish...\n",
            "force_separate_z: None interpolation order: 1\n",
            "separate z: True lowres axis [0]\n",
            "separate z, order in z is 0 order inplane is 1\n",
            "postprocessing...\n"
          ]
        }
      ],
      "source": [
        "!nnUNet_predict --input_folder {os.environ[\"nnUNet_preprocessed\"]} \\\n",
        "                --output_folder {os.environ[\"RESULTS_FOLDER\"]} \\\n",
        "                --task_name \"Task024_Promise\" --model $model_type \\\n",
        "                --save_npz \\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCVDdLjxkSI6"
      },
      "source": [
        "# Resamplings preds back to input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-RWW-i50yvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c8e2d1-b3bc-4122-a663-341461d32387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "search path for t2 : /content/prostateX/nii/ProstateX-0046/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345/**/*T2.nii.gz\n",
            "t2_path found : /content/prostateX/nii/ProstateX-0046/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345/1.3.6.1.4.1.14519.5.2.1.7311.5101.166265209513832781969059787909_MR/1.3.6.1.4.1.14519.5.2.1.7311.5101.16626520951383278196905978_MR_T2.nii.gz\n",
            "pred path : /content/nnUNet/output/preds/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345_ProstateX-0046.nii.gz\n"
          ]
        }
      ],
      "source": [
        "for pred_path in sorted(glob.glob(os.path.join(os.environ[\"RESULTS_FOLDER\"], \"*.nii.gz\"))):\n",
        "  search_t2_path = os.path.join(os.environ[\"qin_prostate_rep_nii\"], pred_path.split('/')[-1].split('_')[1][:-7], \n",
        "                                   pred_path.split('/')[-1].split('_')[0], \"**\", \n",
        "                                   \"*T2.nii.gz\")\n",
        "  print(f\"search path for t2 : {search_t2_path}\")\n",
        "  t2_path = glob.glob(search_t2_path, recursive=True)[0]                              \n",
        "  print(f\"t2_path found : {t2_path}\")\n",
        "  print(f\"pred path : {pred_path}\")\n",
        "  resample_args_to_t2_origin = {\"input\" : pred_path, \n",
        "                        \"output\" : os.path.join(os.environ[\"nnUNet_preds_resampled\"], \n",
        "                                                pred_path.split('/')[-1]),\n",
        "                        \"fixed\" : t2_path,\n",
        "                        \"interpolation\" : \"nn\"}\n",
        "  path_log = 'log_pypla_res_pred' + pred_path.split('/')[-1].split('.')[0] + '.txt'            \n",
        "  !touch path_log\n",
        "  pypla.resample(verbose = False, **resample_args_to_t2_origin, path_to_log_file=path_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljlV3z5PN-vF"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQus28YQiZlD"
      },
      "source": [
        "## Functions aiming to retrieve right ground truth labelsID per nnUnet prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPelDT5HhnQt"
      },
      "outputs": [],
      "source": [
        "def retrieve_seg_labelID(input_path_json, categoryCode = 'Anatomical Structure', typeCode ='Prostate'):\n",
        "  #read json file\n",
        "  json_dic = json.load(open(input_path_json))\n",
        "  for seg in json_dic['segmentAttributes']:\n",
        "    cat_code = seg[0].get('SegmentedPropertyCategoryCodeSequence').get('CodeMeaning')\n",
        "    type_code = seg[0].get('SegmentedPropertyTypeCodeSequence').get('CodeMeaning')\n",
        "    current_labelID = seg[0].get('labelID')\n",
        "    if categoryCode == cat_code and typeCode == type_code:\n",
        "      return current_labelID\n",
        "  return ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNgL8vsViYwe"
      },
      "outputs": [],
      "source": [
        "def get_seg_per_mod(input_path_lst, categoryCode = 'Anatomical Structure', typeCode ='Prostate'):\n",
        "  res_lst = []\n",
        "  for nii_file in input_path_lst:\n",
        "    nii_file_patientID = nii_file.split('/')[-1].split('_')[-1][:-7]\n",
        "    nii_file_studyInstanceUID = nii_file.split('/')[-1].split('_')[0]\n",
        "    serieUID_seg = selection_df[(selection_df.PatientID == nii_file_patientID) \\\n",
        "                                & (selection_df.StudyInstanceUID == nii_file_studyInstanceUID) \\\n",
        "                                & (selection_df.Modality == \"SEG\")][\"SeriesInstanceUID\"].iloc[0]\n",
        "    json_path = glob.glob(os.path.join(os.environ[\"qin_prostate_rep_nii\"], \n",
        "                                       nii_file_patientID, \n",
        "                                       nii_file_studyInstanceUID, \n",
        "                                       serieUID_seg+\"_SEG\", \"*.json\"))[0] \n",
        "    labelID = retrieve_seg_labelID(json_path,\n",
        "                                   categoryCode = ground_truth_cat_CodeMeaning, \n",
        "                                   typeCode = ground_truth_type_CodeMeaning)                              \n",
        "    res_lst.append(os.path.join(os.environ[\"qin_prostate_rep_nii\"], \n",
        "                                nii_file_patientID, \n",
        "                                nii_file_studyInstanceUID, \n",
        "                                serieUID_seg+\"_SEG\", str(labelID)+\".nii.gz\"))\n",
        "  return res_lst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZfPf9It60PH"
      },
      "source": [
        "## Dice score computation "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "prlucYcRISkD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rPyOjc1Uu8N"
      },
      "outputs": [],
      "source": [
        "!rm -rf {os.environ[\"qin_prostate_rep_analysis_verbose\"]}#analysis_verbose/\n",
        "!mkdir -p {os.environ[\"qin_prostate_rep_analysis_verbose\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD0iJk4BuqA3"
      },
      "source": [
        "### Compute dice score between preds and ground truth and store the results into analysis folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZUig0RUDEnF"
      },
      "outputs": [],
      "source": [
        "ref_path_lst = get_seg_per_mod(sorted(glob.glob(os.path.join(os.environ['nnUNet_preds_resampled'], \n",
        "                                                             \"**\", \"*.nii.gz\"), recursive=True)))\n",
        "for ref_path in sorted(ref_path_lst):\n",
        "  ref_path_PatientID = ref_path.split('/')[-4]#ref_path.split('/')[-1].split('_')[-1][:-7]\n",
        "  ref_path_StudyInstanceUID = ref_path.split('/')[-3]#ref_path.split('/')[-1].split('_')[0]\n",
        "  test_path = glob.glob(os.path.join(os.environ[\"nnUNet_preds_resampled\"], \n",
        "                                     '_'.join([ref_path_StudyInstanceUID, ref_path_PatientID]) + '.nii.gz'))[0]\n",
        "  output_path = os.environ[\"qin_prostate_rep_analysis_verbose\"]\n",
        "  if not os.path.exists(output_path):\n",
        "    !mkdir -p $output_path \n",
        "  log_path = test_path.split('/')[-1][:-7]+\"_dice_score_verbose.txt\"\n",
        "  !echo \"ref_path {ref_path}\" > {os.path.join(output_path,log_path)}\n",
        "  !echo \"test_path {test_path}\" >> {os.path.join(output_path,log_path)}\n",
        "  !plastimatch dice --all $ref_path $test_path >> {os.path.join(output_path,log_path)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvTMpuBWuxF6"
      },
      "source": [
        "### store dice score into dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYEKslkDQ8w_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d92eca-52e0-457a-f819-5e057be7af59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------\n",
            "average dice score : 0.910675\n",
            "-----------------------\n",
            "\n",
            "study : 1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345\n",
            "patientID : ProstateX-0046\n",
            "ground truth seg path : /content/prostateX/nii/ProstateX-0046/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345/1.2.276.0.7230010.3.1.3.1070885483.8220.1599221770.50_SEG/1.nii.gz\n",
            "pred seg masks nnunet path : /content/nnUNet/output/preds_resampled/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345_ProstateX-0046.nii.gz\n",
            "dice_score : 0.910675\n",
            "center mass ref : -9.61745 -3.44764 43.7799\n",
            "center mass pred : -8.78923 -2.84516 44.6373\n",
            "hausdorff_dist : 6.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dice_dic = {}\n",
        "#iterate txt logs for dice_score computation\n",
        "for txt_file in sorted(glob.glob(os.path.join(os.environ[\"qin_prostate_rep_analysis_verbose\"], \"*.txt\"))): \n",
        "  with open(txt_file, encoding='utf8') as f:\n",
        "    #variable placeholders for txt file info -- temporary\n",
        "    pholder_dice = ''\n",
        "    pholder_center_mass_pred = ''\n",
        "    pholder_center_mass_ref = ''\n",
        "    pholder_hsdrff = ''\n",
        "    pholder_ref = ''\n",
        "    pholder_test = ''\n",
        "    for line in f:\n",
        "        if \"DICE\" in line:\n",
        "          pholder_dice = float(line.strip().split()[-1])\n",
        "        elif \"ref\" in line and len(line.strip().split()) > 2:\n",
        "          pholder_center_mass_ref = ' '.join([line.strip().split()[-3], \n",
        "                                             line.strip().split()[-2], line.strip().split()[-1]])\n",
        "        elif \"cmp\" in line and len(line.strip().split()) > 2:\n",
        "          pholder_center_mass_pred = ' '.join([line.strip().split()[-3], \n",
        "                                             line.strip().split()[-2], line.strip().split()[-1]])                                             \n",
        "        elif len(line.strip().split()) <= 5 and 'Hausdorff distance' in line:\n",
        "          pholder_hsdrff = float(line.strip().split()[-1])\n",
        "        elif \"ref_path\" in line:\n",
        "          pholder_ref = str(line.strip().split()[-1]) \n",
        "        elif \"test_path\" in line:\n",
        "          pholder_test = str(line.strip().split()[-1])\n",
        "        else:\n",
        "          pass\n",
        "    study = txt_file.split('/')[-1][:-4].split('_')[0] #retrieve studyInstanceUID from txt file name \n",
        "    patientID = txt_file.split('/')[-1][:-4].split('_')[-4] #retrieve patientID\n",
        "    # push values to dict\n",
        "    dice_dic[study] = {'PatientID' : patientID,\n",
        "                       'dice_score' : pholder_dice, \n",
        "                       'center_mass_pred' : pholder_center_mass_pred,\n",
        "                       'center_mass_ref' : pholder_center_mass_ref,\n",
        "                       'hausdorff_dist' : pholder_hsdrff,\n",
        "                       'ground_truth_seg_path' : pholder_ref,\n",
        "                       'pred_nnnet_path' : pholder_test}            \n",
        "\n",
        "print('-----------------------')\n",
        "print(f\"average dice score : {np.average(np.array([val['dice_score'] \\\n",
        "                                                   for val in dice_dic.values()]))}\")\n",
        "print('-----------------------')\n",
        "print()\n",
        "for key,val in dice_dic.items():\n",
        "  study = key\n",
        "  patientID = val[\"PatientID\"]\n",
        "  dice_score = val[\"dice_score\"]\n",
        "  cm_pred = val[\"center_mass_pred\"]\n",
        "  cm_ref = val[\"center_mass_ref\"]\n",
        "  hausdorff_dist = val[\"hausdorff_dist\"]\n",
        "  gt_path = val[\"ground_truth_seg_path\"]\n",
        "  pred_path = val[\"pred_nnnet_path\"]\n",
        "  print(f\"study : {study}\")\n",
        "  print(f\"patientID : {patientID}\")\n",
        "  print(f\"ground truth seg path : {gt_path}\")\n",
        "  print(f\"pred seg masks nnunet path : {pred_path}\")\n",
        "  print(f\"dice_score : {dice_score}\")\n",
        "  print(f\"center mass ref : {cm_ref}\")\n",
        "  print(f\"center mass pred : {cm_pred}\")\n",
        "  print(f\"hausdorff_dist : {hausdorff_dist}\")\n",
        "  print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save dice_score to csv\n",
        "with open(os.path.join(os.environ['qin_prostate_rep_analysis'], 'analysis_metrics.csv'), 'w') as f:\n",
        "    f.write(\"StudyInstanceUID,PatientID,dice_score,center_mass_ref,center_mass_pred,hausdorff_dist, ground_truth_seg_path, pred_nnnet_path\\n\")\n",
        "    for key,val in dice_dic.items():\n",
        "      study = str(key)\n",
        "      patientID = str(val[\"PatientID\"])\n",
        "      dice_score = float(val[\"dice_score\"])\n",
        "      cm_pred = str(val[\"center_mass_pred\"])\n",
        "      cm_ref = str(val[\"center_mass_ref\"])\n",
        "      hausdorff_dist = float(val[\"hausdorff_dist\"])\n",
        "      gt_path = str(val[\"ground_truth_seg_path\"])\n",
        "      pred_path = str(val[\"pred_nnnet_path\"])\n",
        "      f.write(f\"{study},{patientID},{dice_score},{cm_ref},{cm_pred},{hausdorff_dist},{gt_path},{pred_path}\\n\")"
      ],
      "metadata": {
        "id": "7VtX2_R2LkjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKaiwUIZ8iLX"
      },
      "source": [
        "### All metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQBpXyKp8gbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9c85ddf-891a-46b6-ee1e-488b0433445e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref path : /content/prostateX/nii/ProstateX-0046/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345/1.2.276.0.7230010.3.1.3.1070885483.8220.1599221770.50_SEG/1.nii.gz\n",
            "test path : /content/nnUNet/output/preds_resampled/1.3.6.1.4.1.14519.5.2.1.7311.5101.158550708873109712754389110345_ProstateX-0046.nii.gz\n",
            "CENTER_OF_MASS\n",
            "ref\t      -9.61745\t      -3.44764\t       43.7799\n",
            "cmp\t      -8.78923\t      -2.84516\t       44.6373\n",
            "TP:         33807\n",
            "TN:       5155906\n",
            "FN:          4939\n",
            "FP:          1693\n",
            "DICE:      0.910675\n",
            "SE:      0.872529\n",
            "SP:      0.999672\n",
            "Hausdorff distance = 6.000000\n",
            "Avg average Hausdorff distance = 0.154935\n",
            "Max average Hausdorff distance = 0.241856\n",
            "Percent (0.95) Hausdorff distance = 1.000000\n",
            "Hausdorff distance (boundary) = 6.000000\n",
            "Avg average Hausdorff distance (boundary) = 0.850059\n",
            "Max average Hausdorff distance (boundary) = 0.937408\n",
            "Percent (0.95) Hausdorff distance (boundary) = 3.258190\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ref_path_lst = get_seg_per_mod(sorted(glob.glob(os.path.join(os.environ['nnUNet_preds_resampled'],                                                              \"**\", \"*.nii.gz\"), recursive=True)))\n",
        "for ref_path in sorted(ref_path_lst):\n",
        "  ref_path_PatientID = ref_path.split('/')[-4]\n",
        "  ref_path_StudyInstanceUID = ref_path.split('/')[-3]\n",
        "  test_path = glob.glob(os.path.join(os.environ[\"nnUNet_preds_resampled\"], \n",
        "                                     '_'.join([ref_path_StudyInstanceUID, ref_path_PatientID]) + '.nii.gz'))[0]\n",
        "  output_path = \"analysis/txt/\"\n",
        "  if not os.path.exists(output_path):\n",
        "    !mkdir -p $output_path \n",
        "  log_path = test_path.split('/')[-1][:-7]+\".txt\"\n",
        "  print(f\"ref path : {ref_path}\")\n",
        "  print(f\"test path : {test_path}\")\n",
        "  !plastimatch dice --all $ref_path $test_path \n",
        "  print()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export results to google drive "
      ],
      "metadata": {
        "id": "LTLUZjwl7pGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define input and output paths for idc_data and nnunet in google drive through colab"
      ],
      "metadata": {
        "id": "0bY8pfbduW7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #path to IDC data\n",
        "# input_idc_data = os.environ[\"qin_prostate_rep_root\"]\n",
        "# output_drive_idc_data = os.path.join(path_experiment, \"idc_data\")\n",
        "# if not os.path.exists(output_drive_idc_data):\n",
        "#   !mkdir -p $output_drive_idc_data\n",
        "  \n",
        "# #path to nnunet preds\n",
        "# input_nnunet = os.environ[\"nnUNet\"]\n",
        "# output_nnunet = os.path.join(path_experiment, \"nnUNet\")\n",
        "# if not os.path.exists(output_nnunet):\n",
        "#   !mkdir -p $output_nnunet"
      ],
      "metadata": {
        "id": "fWHQh8oVwBu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #sanity checks regarding storage size\n",
        "# ##data\n",
        "# !du -sh $input_idc_data\n",
        "# ##preds\n",
        "# !du -sh $input_nnunet"
      ],
      "metadata": {
        "id": "-V1HAuUVwJm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy data to drive"
      ],
      "metadata": {
        "id": "bi3JRLw40kXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #copy idc data\n",
        "# %cp -av $input_idc_data $output_drive_idc_data\n",
        "# #verbose True, keep same struct as input\n",
        "# #copy nnunet data\n",
        "# %cp -av $input_nnunet $output_nnunet"
      ],
      "metadata": {
        "id": "OT9uV19h8CVC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "idc-prostate_segmentation_promised24_prostateX.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}